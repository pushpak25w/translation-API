{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15d35135-48e5-4792-bf85-3aebc68a2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb4330a7-db70-477b-ae98-40db92d85b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190206, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_table('./dataset/french.txt',names=['lang','trans','useless'])\n",
    "data.drop('useless',axis=1,inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "065c0b2d-c4a8-4e28-9d8c-5068595fcba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Marche.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Bouge !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang    trans\n",
       "0  Go.     Va !\n",
       "1  Go.  Marche.\n",
       "2  Go.  Bouge !\n",
       "3  Hi.  Salut !\n",
       "4  Hi.   Salut."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1=data\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "992779f0-c3ec-4565-b583-1b9f972656a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data1\n",
    "spchrs=set(string.punctuation)\n",
    "lowerCase=lambda x:x.lower()\n",
    "quotes=lambda x:re.sub(\"'\",'',x)\n",
    "specialCh=lambda x:''.join(ch for ch in x if ch not in spchrs)\n",
    "rmDigits=lambda x:x.translate(str.maketrans('','',digits))\n",
    "spaces=lambda x:x.strip()\n",
    "unwanted=lambda x:re.sub(\" +\",\" \",x)\n",
    "startEnd=lambda x:'START_'+x+'_END'\n",
    "data.lang=data.lang.apply(lowerCase)\n",
    "data.lang=data.lang.apply(quotes)\n",
    "data.lang=data.lang.apply(specialCh)\n",
    "data.lang=data.lang.apply(rmDigits)\n",
    "data.lang=data.lang.apply(spaces)\n",
    "data.lang=data.lang.apply(unwanted)\n",
    "data.trans=data.trans.apply(lowerCase)\n",
    "data.trans=data.trans.apply(quotes)\n",
    "data.trans=data.trans.apply(specialCh)\n",
    "data.trans=data.trans.apply(rmDigits)\n",
    "data.trans=data.trans.apply(spaces)\n",
    "data.trans=data.trans.apply(unwanted)\n",
    "data.trans=data.trans.apply(startEnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62e6de5e-7a2b-410e-adeb-15090dcb029f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13393</th>\n",
       "      <td>help us please</td>\n",
       "      <td>START_aideznous sil vous plaît_END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26150</th>\n",
       "      <td>tom will obey you</td>\n",
       "      <td>START_tom tobéira_END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12136</th>\n",
       "      <td>we volunteered</td>\n",
       "      <td>START_nous nous portâmes volontaires_END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66472</th>\n",
       "      <td>you dont even know how</td>\n",
       "      <td>START_tu ne sais même pas comment_END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>were boys</td>\n",
       "      <td>START_nous sommes des garçons_END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152202</th>\n",
       "      <td>he responded to her offer with a laugh</td>\n",
       "      <td>START_il a répondu à sa proposition par des ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104799</th>\n",
       "      <td>dont you want to come inside</td>\n",
       "      <td>START_ne veuxtu pas venir à lintérieur_END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158241</th>\n",
       "      <td>you dont have to go unless you want to</td>\n",
       "      <td>START_vous nêtes pas obligés dy aller à moins ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89011</th>\n",
       "      <td>why are we studying french</td>\n",
       "      <td>START_pourquoi étudionsnous le français_END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35065</th>\n",
       "      <td>i like each of them</td>\n",
       "      <td>START_jaime chacun dentre eux_END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          lang  \\\n",
       "13393                           help us please   \n",
       "26150                        tom will obey you   \n",
       "12136                           we volunteered   \n",
       "66472                   you dont even know how   \n",
       "2532                                 were boys   \n",
       "152202  he responded to her offer with a laugh   \n",
       "104799            dont you want to come inside   \n",
       "158241  you dont have to go unless you want to   \n",
       "89011               why are we studying french   \n",
       "35065                      i like each of them   \n",
       "\n",
       "                                                    trans  \n",
       "13393                  START_aideznous sil vous plaît_END  \n",
       "26150                               START_tom tobéira_END  \n",
       "12136            START_nous nous portâmes volontaires_END  \n",
       "66472               START_tu ne sais même pas comment_END  \n",
       "2532                    START_nous sommes des garçons_END  \n",
       "152202  START_il a répondu à sa proposition par des ri...  \n",
       "104799         START_ne veuxtu pas venir à lintérieur_END  \n",
       "158241  START_vous nêtes pas obligés dy aller à moins ...  \n",
       "89011         START_pourquoi étudionsnous le français_END  \n",
       "35065                   START_jaime chacun dentre eux_END  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42aaf547-c22c-49b8-b878-36fad3f376e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "langVocab=set()\n",
    "for line in data.lang:\n",
    "    for word in line.split():\n",
    "        langVocab.add(word)\n",
    "transVocab=set()\n",
    "for line in data.trans:\n",
    "    for word in line.split():\n",
    "        transVocab.add(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad46d31e-62aa-4987-a3e4-dfb64e1cf342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "maxSrcLen=0\n",
    "for line in data.lang:\n",
    "    maxSrcLen=max(maxSrcLen,len(line.split()))\n",
    "print(maxSrcLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eae6328d-1136-4353-9c40-015db981e17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "maxTarLen=0\n",
    "for line in data.trans:\n",
    "    maxTarLen=max(maxTarLen,len(line.split()))\n",
    "print(maxTarLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f083e7d-04dd-4a99-a8e1-3f2c11cde30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43869 15359\n"
     ]
    }
   ],
   "source": [
    "inputWords=sorted(list(langVocab))\n",
    "targetWords=sorted(list(transVocab))\n",
    "lenOfEncoderTokens=len(langVocab)\n",
    "lenOfDecoderTokens=len(transVocab)\n",
    "print(lenOfDecoderTokens,lenOfEncoderTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfe58dd7-c91b-4462-a8dc-aa928ddad1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43870"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenOfDecoderTokens+=1\n",
    "lenOfDecoderTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00f90b06-3f6d-4a79-841b-00cf1a6542cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tarTokenInd,inpRevIndMap,tarRevIndMap,inpTokenInd={},{},{},{}\n",
    "for i,word in enumerate(inputWords):\n",
    "    inpTokenInd[word]=i+1\n",
    "    inpRevIndMap[i]=word\n",
    "for i,word in enumerate(targetWords):\n",
    "    tarTokenInd[word]=i+1\n",
    "    tarRevIndMap[i]=word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6ffd5d9-5b99-4711-b3c2-45319f65740c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181837</th>\n",
       "      <td>i wonder how many people in australia can spea...</td>\n",
       "      <td>START_je me demande combien de personnes en au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138449</th>\n",
       "      <td>tom told the children many stories</td>\n",
       "      <td>START_tom raconta beaucoup dhistoires aux enfa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189263</th>\n",
       "      <td>when was the last time you used benzodiazepine...</td>\n",
       "      <td>START_quand avezvous pris pour la dernière foi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50444</th>\n",
       "      <td>thanks for the cookie</td>\n",
       "      <td>START_merci pour le cookie_END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50041</th>\n",
       "      <td>nothing lasts forever</td>\n",
       "      <td>START_rien ne dure pour toujours_END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     lang  \\\n",
       "181837  i wonder how many people in australia can spea...   \n",
       "138449                 tom told the children many stories   \n",
       "189263  when was the last time you used benzodiazepine...   \n",
       "50444                               thanks for the cookie   \n",
       "50041                               nothing lasts forever   \n",
       "\n",
       "                                                    trans  \n",
       "181837  START_je me demande combien de personnes en au...  \n",
       "138449  START_tom raconta beaucoup dhistoires aux enfa...  \n",
       "189263  START_quand avezvous pris pour la dernière foi...  \n",
       "50444                      START_merci pour le cookie_END  \n",
       "50041                START_rien ne dure pour toujours_END  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=shuffle(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f08e8561-0b24-4a91-af3f-5ca8b53d1a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=data.lang,data.trans\n",
    "x_train,x_test,y_train,y_test=train=train_test_split(x,y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab6a739a-cc73-4de1-af11-2fd2e9b14706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x=x_train,y=y_train,size=128):\n",
    "    while True:\n",
    "        for i1 in range(0,len(x),size):\n",
    "            encInp=np.zeros((size,maxSrcLen),dtype='float32')\n",
    "            decInp=np.zeros((size,maxTarLen),dtype='float32')\n",
    "            decTar=np.zeros((size,maxTarLen,lenOfDecoderTokens),dtype='float32')\n",
    "            for i2,(inpText,tarText) in enumerate(zip(x[i1:i1+size],y[i1:i1+size])):\n",
    "                for i3,word in enumerate(inpText.split()):\n",
    "                    encInp[i2,i3]=inpTokenInd[word]\n",
    "                tarTextSplit=tarText.split()\n",
    "                for i3,word in enumerate(tarTextSplit):\n",
    "                    if i3<len(tarTextSplit)-1:\n",
    "                        decInp[i2,i3]=tarTokenInd[word]=tarTokenInd[word]\n",
    "                    if i3>0:\n",
    "                        decTar[i2,i3-1,tarTokenInd[word]]=1\n",
    "            yield([encInp,decInp],decTar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffd30024-444b-47ee-8a3f-501045a6b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims=50\n",
    "encInp=Input(shape=(None,))\n",
    "encEmb=Embedding(lenOfEncoderTokens,dims,mask_zero=True)(encInp)\n",
    "encLSTM=LSTM(dims,return_state=True)\n",
    "encOut,stateH,stateC=encLSTM(encEmb)\n",
    "encStates=[stateH,stateC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae938962-6874-477f-938c-ff886fa06e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decInp=Input(shape=(None,))\n",
    "decEmbLayer=Embedding(lenOfDecoderTokens,dims,mask_zero=True)\n",
    "decEmb=decEmbLayer(decInp)\n",
    "decLSTM=LSTM(dims,return_sequences=True,return_state=True)\n",
    "decOut,_,_=decLSTM(decEmb,initial_state=encStates)\n",
    "decDense=Dense(lenOfDecoderTokens,activation='softmax')\n",
    "decOut=decDense(decOut)\n",
    "model=Model([encInp,decInp],decOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5739f06f-b91c-4902-bddc-bf76ff10a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fae265ea-c7af-4481-a4eb-bcadc0377d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLen=len(x_train)\n",
    "testLen=len(x_test)\n",
    "size=128\n",
    "epochs=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ef95282-008d-458f-b70a-2c0defa5fe1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'he'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16901/1955108930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/env06/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1048\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1051\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/env06/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/env06/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/env06/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    834\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16901/1238765018.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(x, y, size)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpText\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarText\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     \u001b[0mencInp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minpTokenInd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0mtarTextSplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarTextSplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'he'"
     ]
    }
   ],
   "source": [
    "model.fit(encode(x_train,y_train,size),steps_per_epoch = trainLen//size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = encode(x_test, y_test,size),\n",
    "                    validation_steps = testLen//size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5078794c-6304-4d7e-bc36-21d1ed6c235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('nmt_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f20c9a-a9dd-4c85-806f-7c78936543e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04522816-cb25-44d9-9153-8f3f678fd584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7380b51b-762c-4a60-906e-0f6e9ce3c210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
